---
title: 'Handling imbalanced data with resampling'
excerpt: "It's not uncommon for data scientists to work on imabalnced data, i.e. such data where classes are not uniformly distributed and one or two classes present a vast majority. Actually, most of classification data is usually imbalanced. To name but a few: medical data to diagnose a condition, fraud detection data, churn client data etc."
permalink: /posts/imbalanced-ml/
tags:
  - imbalanced
  - resampling
---

<div style="text-align: justify;">It's not uncommon for data scientists to work on imabalnced data, i.e. such data where classes are not uniformly distributed and one or two classes present a vast majority. Actually, most of classification data is usually imbalanced. To name but a few: medical data to diagnose a condition, fraud detection data, churn client data etc.</div>
<p>
<div style="text-align: justify;">The problem here is that machine learning algorithms may overfit on the majority class and totally ignore the minor classes. At the same time, it is the minority class samples (a rare disease or a fraudulent transaction) that we are interested in detecting! One of the ways to overcome the problem of imbalanced data is resampling, i.e. changing the number of samples in the different classes. There are at least three ways to resample data:</div>
<p>

<ul>  
  <li>Oversampling: adding the minory class samples.</li>
  <li>Undersampling: deleting the majority class samples.</li>
  <li>Combination of oversampling and udnersampling.</li>
</ul>

<div style="text-align: justify;">In this post we will examine some popular resampling techniques as well as discover why Accuracy is not always a good evaluation metric.</div>

<div style="text-align: justify;">First, we will look at different resampling methods in action and plot the results. Afterwards we are going to create a classification model on imbalanced data with and without resampling.</div>

<h2>Resampling on synthetic data</h2>
<h3>Generate imbalanced data</h3>
<div style="text-align: justify;">Let's create some imbalanced data to demonstrate the differene between resampling methods.</div>
<p>
<script src="https://gist.github.com/maya-ami/66f9bb3c1afa7c27fda563d3a251ddc0.js"></script>
<p>
<img src="/images/im_data.png">
<p>

<h3>Random oversampling</h3>
<div style="text-align: justify;">First, let's try the most naive approach - random oversampling. This will create a duplicate samples of a minor class.</div>
<p>
  <script src="https://gist.github.com/maya-ami/4eb0c5793431ae1379c8e19e27561ca6.js"></script>
<p>
  <img src="/images/ros.png">
<p>

<h3>SMOTE</h3>
<div style="text-align: justify;">A more advanced method - SMOTE (Synthetic Minority Oversampling Technique) - doesn't just duplicate an existing sample. SMOTE generates a new sample considering its k neareast-neighbors.</div>
<p>
  <script src="https://gist.github.com/maya-ami/395107e16863e0881a11814163fc55f5.js"></script>
<p>
  <img src="/images/smote.png">

<div style="text-align: justify;">The plot shows that SMOTE generates many "noisy" samples that are placed between the outliers and the true minor samples.</div>
<p>


<h3>SMOTEEN</h3>
<div style="text-align: justify;">To solve this problem, one may use any of "cleaning" undersampling methods. For instance, SMOTEEN (SMOTE + Edited Nearest Neighbours) generates new samples as a vanila SMOTE, but then deletes those which class is different from the k-nearest neighbours' class.</div>
<p>
  <script src="https://gist.github.com/maya-ami/a7daa304ad814b36510ad272117d7214.js"></script>
<p>
  <img src="/images/smoteenn.png">


<h3>Random undersampling</h3>
<div style="text-align: justify;">The plot below shows how random undersampling, i.e. random deletion of major class samples, work.</div>
<p>
  <script src="https://gist.github.com/maya-ami/b6a686b862e229a8836fae30f9e133c9.js"></script>
<p>
  <img src="/images/rus.png">


<h3>Near Miss</h3>
<div style="text-align: justify;">Another undersampling method - Near Miss - deletes the major class samples for which the average distance to the N closest samples of the minor class is the smallest.</div>
<p>
  <script src="https://gist.github.com/maya-ami/677abf8d3d7b6cf06e4b07d623c99168.js"></script>
<p>
  <img src="/images/miss.png">



<h2>Resampling on real data</h2>

<div style="text-align: justify;">Now that we have a basic idea how different resampling approaches work, let's try to apply this knowledge in a real classification task. We are provided with the information about <a href="https://www.kaggle.com/sonujha090/bank-marketing">the results of a bank marketing campaign</a>. Our task is to predict whether the client signs a term deposit.</div>

<div style="text-align: justify;">Let's get the data and look at the distribution of the target variable.</div>
<p>
  <script src="https://gist.github.com/maya-ami/b5795d95c83dff88f1f7bb9442537829.js"></script>
<p>
  <img src="/images/target-distrib.png">


<div style="text-align: justify;">It's clear that the data is imbalanced. There is much more information on people who declined to sign a deposit. To process the data further, let's transform some categorical features that need to be encoded.</div>
<p>
  <script src="https://gist.github.com/maya-ami/a38abe7a1adcb44e7210d8934d910215.js"></script>
<p>


<div style="text-align: justify;">Some other categorical variables will be encode with the help of ohe-hot encoding, i.e. each category of a feature will be now represented as a separate column.</div>
<p>
  <script src="https://gist.github.com/maya-ami/e89e1c968ea6ba34badbbbf8b003b94b.js"></script>
<p>

<div style="text-align: justify;">Index(['age', 'education', 'default', 'balance', 'housing', 'loan', 'day',
       'month', 'duration', 'campaign', 'pdays', 'previous', 'y',
       'job_blue-collar', 'job_entrepreneur', 'job_housemaid',
       'job_management', 'job_retired', 'job_self-employed', 'job_services',
       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',
       'marital_married', 'marital_single'],
      dtype='object')</div>

<p>
<div style="text-align: justify;">Let's separate the target variable from the rest of the feautures and create train and test sets. <b>NB</b>: Don't forget to use stratification when splitting the data into train and test. This will help to preserve the same class distribution as in the whole dataset.</div>
<p>
  <script src="https://gist.github.com/maya-ami/735ff9c5edbaa125f81e154c16df45e0.js"></script>
<p>
  <img src="/images/train_test.png">
<p>

<h2>Baseline: logistic regression on imbalanced dataset</h2>
<p>
  <script src="https://gist.github.com/maya-ami/ad44b2c9dfa05ee4f90d3c86502a09be.js"></script>
<p>
<div style="text-align: justify;">Accuracy: 0.891</div>
<p>


<div style="text-align: justify;">Wow great! 89% of accurate predictions with a simple model. But should we really trust this metric? Let's take a closer look at the performance of the classifier. A confusion matrix and a classification report will be quite handy in this case.</div>

<img src="/images/lr_cm.png">
<p>
<div style="text-align: justify;">Accuracy: 0.891</div>
<div style="text-align: justify;">Recall: 0.192</div>
<p>

<div style="text-align: justify;">Here it is! Recall for class 1 - the class we are actually interested in - is lower 20%. What does that mean?</div>
<p>
<div style="text-align: justify;">Well, let's imagine that this classifier is used in production, i.e. the marketing dept is relying on the model to identify people that would likely sign a term deposit. Do you see it now? We have effectively missed 80% of the potential clients!</div>
<p>
<div style="text-align: justify;">In order to minimize the number of such misses, we need to pay closer attention to recall rather than relying solely on accuracy.</div>

<h2>The right way to use resampling:</h2>
<ol>
  <li>Split your data in train and test sets.</li>
  <li>Resample <b>only</b> the train set!</li>
  <li>Estimate the classification quality on the test set.</li>
</ol>


<div style="text-align: justify;">Violating this procedure may lead to an inadequate evaluation results. For example, if you first resample and split your data, the same sample may be found in both train and test sets. This would be a leakage of data - the model is tested on an object that was present in the train.</div>
<p>
<img src="/images/resampling.png">
<p>


<h2>Oversampling</h2>
<h3>Random Oversampling</h3>
<div style="text-align: justify;">This approach simply duplicates existing samples of a minor class.</div>
<p>
  <script src="https://gist.github.com/maya-ami/526f0153d281c6e3d3fd4b2a4403c9e4.js"></script>
<p>
  <img src="/images/ros_cm.png">
<p>
<div style="text-align: justify;">Accuracy: 0.798</div>
<div style="text-align: justify;">Recall: 0.728</div>
<p>


<h3>SMOTE</h3>
<div style="text-align: justify;">SMOTE generates new minor class samples by means of interpolation.</div>
<p>
  <script src="https://gist.github.com/maya-ami/110b21a7dfbb2b08a1f91ce1429e1bae.js"></script>
<p>
  <img src="/images/smote_cm.png">
<p>
<div style="text-align: justify;">Accuracy: 0.793</div>
<div style="text-align: justify;">Recall: 0.715</div>
<p>




<h2>Undersampling</h2>
<h3>Random Undersampling</h3>
<div style="text-align: justify;">Randomly delete some objects of major class.</div>
<p>
  <script src="https://gist.github.com/maya-ami/a6e5803ca725aca5a47637d309dd22de.js"></script>
<p>
  <img src="/images/rus_cm.png">
<p>
<div style="text-align: justify;">Accuracy: 0.796</div>
<div style="text-align: justify;">Recall: 0.728</div>
<p>



<h2>Combination of oversampling и undersampling</h2>
<div style="text-align: justify;">SMOTE with Tomek's links:</div>
<ol>
  <li>Generate new samples with SMOTE.</li>
  <li>Delete objects that create Tomek's link. A Tomek’s link exist if the two samples are the nearest neighbors of each other.</li>
</ol>
<p>
  <script src="https://gist.github.com/maya-ami/219597b10decdef07616d9d8f9d7757a.js"></script>
<p>
  <img src="/images/smote_tomek_cm.png">
<p>
<div style="text-align: justify;">Accuracy: 0.795</div>
<div style="text-align: justify;">Recall: 0.735</div>
<p>

<h2>Wrapping up</h2>
<div style="text-align: justify;">In this post, we have presented a few approaches to handle imbalanced data. We've seen how misleading can be such a metric as Accuracy in case of class imbalance. We've also given a closer look to differences between some resampling techniques. </div>
